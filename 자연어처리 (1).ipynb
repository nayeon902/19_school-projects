{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#https://datascienceschool.net/03%20machine%20learning/03.01.01%20NLTK%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%ED%8C%A8%ED%82%A4%EC%A7%80.html\n",
        "#위에 사이트에 설명 친절하게 되어있으니 참고하세요!, 그리고 #은 설명넣을때 쓰는거라 코드에 아무 영향 없음(지워도됨)"
      ],
      "metadata": {
        "id": "oOuMZkP1HK9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmjiqQIr65qt",
        "outputId": "cc415cd7-9429-4c57-bfc7-4c937cbff2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "#nltk 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk #nltk를 사용한다고 먼저 선언\n",
        "nltk.download('punkt') #nltk안에서 punkt 모듈을 사용할것이므로 다운, pukt는 문장 구조를 학습한 일종의 모델로 어떤 것이 약어에 쓰이는지 (예를 들어 Ph.D.) 어떤 것이 마침표인지 학습이 되어있음. 문장은 기본적으로 마침표를 기준으로 나누고 약어는 학습된 대로 한 단어로 취급함.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSGGPWb27CYM",
        "outputId": "1431e5f5-18d2-45be-da99-7d8d0c89eef1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰이란 문법적으로 더 이상 나눌 수 없는 언어요소. 텍스트 토큰화란 말뭉치로부터 토큰을 분리하는 작업\n",
        "sentence=\"Learning Python is very exciting and fun. Enjoy Python!\"#sentence라는 객체를 만들고 문장을 입력, 이 문장이 말뭉치(Corpus)에 해당함\n",
        "tokens=nltk.word_tokenize(sentence) #tekens 객체를 만든 후에 말뭉치에서 각각의 토큰들을 분리하여 저장 \n",
        "tokens #객체를 출력, 출력하면 각 토큰들이 배열로 저장된 것을 확인할 수 있음."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsTwEbft7SH-",
        "outputId": "a9ec4e84-0201-4eb6-a293-f23201e4efa3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Learning',\n",
              " 'Python',\n",
              " 'is',\n",
              " 'very',\n",
              " 'exciting',\n",
              " 'and',\n",
              " 'fun',\n",
              " '.',\n",
              " 'Enjoy',\n",
              " 'Python',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#추가로 품사 태깅--> 태깅: 콜렉션의 각 단어에 품사를 붙이는 절차, 품사에 따라 발음 시 강세가 달라지므로 품사를 알아내서 정확한 단어의 의미를 얻는작업"
      ],
      "metadata": {
        "id": "ISvVF7HXHgxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=nltk.Text(nltk.word_tokenize(sentence)) #데이터전처리의 일종, 위 문자열을 단어단위로 토큰화해서 다시 객체에 저장함\n",
        "text #객체를 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRamuCvy7k--",
        "outputId": "27ab396f-bbb8-456f-d9e5-857d5084090a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: Learning Python is very exciting and fun ....>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(text) #설명서 text,common_contexts, concordance, similar부분정도 보면 도움될듯. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "burwA92VD_cy",
        "outputId": "4ef67261-43ed-4c00-e6fc-7d5ab95a5ff6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on Text in module nltk.text object:\n",
            "\n",
            "class Text(builtins.object)\n",
            " |  Text(tokens, name=None)\n",
            " |  \n",
            " |  A wrapper around a sequence of simple (string) tokens, which is\n",
            " |  intended to support initial exploration of texts (via the\n",
            " |  interactive console).  Its methods perform a variety of analyses\n",
            " |  on the text's contexts (e.g., counting, concordancing, collocation\n",
            " |  discovery), and display the results.  If you wish to write a\n",
            " |  program which makes use of these analyses, then you should bypass\n",
            " |  the ``Text`` class, and use the appropriate analysis function or\n",
            " |  class directly instead.\n",
            " |  \n",
            " |  A ``Text`` is typically initialized from a given document or\n",
            " |  corpus.  E.g.:\n",
            " |  \n",
            " |  >>> import nltk.corpus\n",
            " |  >>> from nltk.text import Text\n",
            " |  >>> moby = Text(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __getitem__(self, i)\n",
            " |  \n",
            " |  __init__(self, tokens, name=None)\n",
            " |      Create a Text object.\n",
            " |      \n",
            " |      :param tokens: The source text.\n",
            " |      :type tokens: sequence of str\n",
            " |  \n",
            " |  __len__(self)\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __str__(self)\n",
            " |      Return str(self).\n",
            " |  \n",
            " |  collocation_list(self, num=20, window_size=2)\n",
            " |      Return collocations derived from the text, ignoring stopwords.\n",
            " |      \n",
            " |          >>> from nltk.book import text4\n",
            " |          >>> text4.collocation_list()[:2]\n",
            " |          [('United', 'States'), ('fellow', 'citizens')]\n",
            " |      \n",
            " |      :param num: The maximum number of collocations to return.\n",
            " |      :type num: int\n",
            " |      :param window_size: The number of tokens spanned by a collocation (default=2)\n",
            " |      :type window_size: int\n",
            " |      :rtype: list(tuple(str, str))\n",
            " |  \n",
            " |  collocations(self, num=20, window_size=2)\n",
            " |      Print collocations derived from the text, ignoring stopwords.\n",
            " |      \n",
            " |          >>> from nltk.book import text4\n",
            " |          >>> text4.collocations() # doctest: +ELLIPSIS\n",
            " |          United States; fellow citizens; four years; ...\n",
            " |      \n",
            " |      :param num: The maximum number of collocations to print.\n",
            " |      :type num: int\n",
            " |      :param window_size: The number of tokens spanned by a collocation (default=2)\n",
            " |      :type window_size: int\n",
            " |  \n",
            " |  common_contexts(self, words, num=20)\n",
            " |      Find contexts where the specified words appear; list\n",
            " |      most frequent common contexts first.\n",
            " |      \n",
            " |      :param words: The words used to seed the similarity search\n",
            " |      :type words: str\n",
            " |      :param num: The number of words to generate (default=20)\n",
            " |      :type num: int\n",
            " |      :seealso: ContextIndex.common_contexts()\n",
            " |  \n",
            " |  concordance(self, word, width=79, lines=25)\n",
            " |      Prints a concordance for ``word`` with the specified context window.\n",
            " |      Word matching is not case-sensitive.\n",
            " |      \n",
            " |      :param word: The target word or phrase (a list of strings)\n",
            " |      :type word: str or list\n",
            " |      :param width: The width of each line, in characters (default=80)\n",
            " |      :type width: int\n",
            " |      :param lines: The number of lines to display (default=25)\n",
            " |      :type lines: int\n",
            " |      \n",
            " |      :seealso: ``ConcordanceIndex``\n",
            " |  \n",
            " |  concordance_list(self, word, width=79, lines=25)\n",
            " |      Generate a concordance for ``word`` with the specified context window.\n",
            " |      Word matching is not case-sensitive.\n",
            " |      \n",
            " |      :param word: The target word or phrase (a list of strings)\n",
            " |      :type word: str or list\n",
            " |      :param width: The width of each line, in characters (default=80)\n",
            " |      :type width: int\n",
            " |      :param lines: The number of lines to display (default=25)\n",
            " |      :type lines: int\n",
            " |      \n",
            " |      :seealso: ``ConcordanceIndex``\n",
            " |  \n",
            " |  count(self, word)\n",
            " |      Count the number of times this word appears in the text.\n",
            " |  \n",
            " |  dispersion_plot(self, words)\n",
            " |      Produce a plot showing the distribution of the words through the text.\n",
            " |      Requires pylab to be installed.\n",
            " |      \n",
            " |      :param words: The words to be plotted\n",
            " |      :type words: list(str)\n",
            " |      :seealso: nltk.draw.dispersion_plot()\n",
            " |  \n",
            " |  findall(self, regexp)\n",
            " |      Find instances of the regular expression in the text.\n",
            " |      The text is a list of tokens, and a regexp pattern to match\n",
            " |      a single token must be surrounded by angle brackets.  E.g.\n",
            " |      \n",
            " |      >>> print('hack'); from nltk.book import text1, text5, text9\n",
            " |      hack...\n",
            " |      >>> text5.findall(\"<.*><.*><bro>\")\n",
            " |      you rule bro; telling you bro; u twizted bro\n",
            " |      >>> text1.findall(\"<a>(<.*>)<man>\")\n",
            " |      monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
            " |      mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
            " |      pale; furious; better; certain; complete; dismasted; younger; brave;\n",
            " |      brave; brave; brave\n",
            " |      >>> text9.findall(\"<th.*>{3,}\")\n",
            " |      thread through those; the thought that; that the thing; the thing\n",
            " |      that; that that thing; through these than through; them that the;\n",
            " |      through the thick; them that they; thought that the\n",
            " |      \n",
            " |      :param regexp: A regular expression\n",
            " |      :type regexp: str\n",
            " |  \n",
            " |  generate(self, length=100, text_seed=None, random_seed=42)\n",
            " |      Print random text, generated using a trigram language model.\n",
            " |      See also `help(nltk.lm)`.\n",
            " |      \n",
            " |      :param length: The length of text to generate (default=100)\n",
            " |      :type length: int\n",
            " |      \n",
            " |      :param text_seed: Generation can be conditioned on preceding context.\n",
            " |      :type text_seed: list(str)\n",
            " |      \n",
            " |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
            " |          makes the random sampling part of generation reproducible. (default=42)\n",
            " |      :type random_seed: int\n",
            " |  \n",
            " |  index(self, word)\n",
            " |      Find the index of the first occurrence of the word in the text.\n",
            " |  \n",
            " |  plot(self, *args)\n",
            " |      See documentation for FreqDist.plot()\n",
            " |      :seealso: nltk.prob.FreqDist.plot()\n",
            " |  \n",
            " |  readability(self, method)\n",
            " |  \n",
            " |  similar(self, word, num=20)\n",
            " |      Distributional similarity: find other words which appear in the\n",
            " |      same contexts as the specified word; list most similar words first.\n",
            " |      \n",
            " |      :param word: The word used to seed the similarity search\n",
            " |      :type word: str\n",
            " |      :param num: The number of words to generate (default=20)\n",
            " |      :type num: int\n",
            " |      :seealso: ContextIndex.similar_words()\n",
            " |  \n",
            " |  vocab(self)\n",
            " |      :seealso: nltk.prob.FreqDist\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.tokens #텍스트 객체 안의 토큰들을 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrI3Lfk87yKa",
        "outputId": "3c0df915-9398-4370-83f1-00956a2f5ce5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Learning',\n",
              " 'Python',\n",
              " 'is',\n",
              " 'very',\n",
              " 'exciting',\n",
              " 'and',\n",
              " 'fun',\n",
              " '.',\n",
              " 'Enjoy',\n",
              " 'Python',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(text.vocab)#직접 궁금한 기능어들 괄호안에 넣어서 그부분만 설명 볼 수도 있음."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErEgorq171eH",
        "outputId": "709cafa9-5da4-41e5-b1d2-1c50561f0f65"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method vocab in module nltk.text:\n",
            "\n",
            "vocab() method of nltk.text.Text instance\n",
            "    :seealso: nltk.prob.FreqDist\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.vocab() #단어의 빈도수를 계산해서 표현해주는 기능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZkQh1_N79hE",
        "outputId": "ab550afc-edb6-42b8-84a9-69047dff8dc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'Python': 2, 'Learning': 1, 'is': 1, 'very': 1, 'exciting': 1, 'and': 1, 'fun': 1, '.': 1, 'Enjoy': 1, '!': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text.vocab()) #총 10개의 단어가 있고 총 11번 사용됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VFCI7XY8Cfw",
        "outputId": "ebdf1d4f-e44c-4c2f-9d2d-2779e32394c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 10 samples and 11 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.plot() #각 토큰의 사용빈도를 그래프로 표현"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "r-0cbchT8L3o",
        "outputId": "78443a5a-48be-42d1-cf23-1f449d07e464"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efe21d04310>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('book') #nlkt에 있는 예시 책들을 다운받음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgKZfVZE8dNz",
        "outputId": "b49777eb-9d57-430c-a720-e19b50c3ed6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.book import * #모든 모듈중에 nlkt.book을 쓰겠다는 의미"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXFk5xSX8qOr",
        "outputId": "f7f597c8-4992-4913-ece5-6680775ffee9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 #이 책의 내용들이 또 하나의 말뭉치가 됨.\n",
        "# 위에 책들 목록에서 text1을 꺼내옴, 1~9 아무거나 사용가능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kUa-BiZ8ydS",
        "outputId": "1b42603b-c4fa-4f89-9002-280a18585583"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: Moby Dick by Herman Melville 1851>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이 소설의 전체 단어 수를 적으시오.\n",
        "len(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHow_gSo9CU3",
        "outputId": "35d663ee-4d41-43d2-f370-c440d8d1a987"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "260819"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(len(text1))+\"개입니다.\" #len은 문자열 길이구하는거, str은 문자열로 전환시키는거. 문자열길이를 문자열로 표현-> 뒤에 개입니다 랑 붙여서 출력하려고 형태 동일하게 맞춘거"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VIHH2eVK9IPp",
        "outputId": "fb60370d-a8ff-487b-df16-4125a6716a19"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'260819개입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이 소설에 나오는 단어 중 중복을 제외한 고유한 단어의 수를 적으시오.\n",
        "len(set(text1)) #set은 집합자료형, 순소가 없고 인덱스가 없는 모음, 집합자료형의 길이를 출력한 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwMKebWk9T-Q",
        "outputId": "814f225f-30b0-4a70-d075-6a798344c56f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19317"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이 책에서 고유한 단어는 보통 몇 번 정도 반복되어 나오는지 알아보자.\n",
        "len(text1)/len(set(text1)) #전체단어를 고유한 단어수로 나눔\n",
        "#텍스트를 구성하고 있는 총 단어 수와 고유한 단어 수를 비교해 보자.\n",
        "#Text객체는 텍스트 단어들로 구성된 리스트라고 생각하면 된다.\n",
        "#따라서, 파이썬 리스트와 거의 비슷하게 조작할 수 있다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAeJx2-v9dk2",
        "outputId": "b0c9b3cb-4345-4c08-e9cb-1422d81da47a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.502044830977896"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모비딕 소설의 단어 빈도를 작성해 보자.\n",
        "text1.vocab() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzkG1WfR9xbu",
        "outputId": "a85a8d2a-4f24-470c-abc2-8c943ed81f1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({',': 18713, 'the': 13721, '.': 6862, 'of': 6536, 'and': 6024, 'a': 4569, 'to': 4542, ';': 4072, 'in': 3916, 'that': 2982, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text1.vocab())#토큰의 갯수와 총 출현 횟수\n",
        "fd=FreqDist(text1.vocab()) #(이 코드 빠져있었음..! 오류나니까 추가하기)\n",
        "#각 토큰의 출현 횟수를 담은 FreqDist(frequency distribution)객체를 반환한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2iJZEtn92-H",
        "outputId": "6708b80d-9853-4bfe-9c0c-61d8d53b03b2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 19317 samples and 260819 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fd) #위에서 fd객체에 넣어놓은 빈도수를 출력(text1.vocab()한거와 같은말이라서 의미없음(위에 코드랑 중복))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7-Od1kk-RDB",
        "outputId": "43c8c49c-de50-47bf-c477-b87f93ccac4f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 19317 samples and 260819 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd.most_common(5) #가장 많이 나온 단어 5개 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BAIbVhp-GJv",
        "outputId": "f2eb4616-6ae8-46ca-e30c-9cde7f0c319b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 18713), ('the', 13721), ('.', 6862), ('of', 6536), ('and', 6024)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlIsnmJ--J8S",
        "outputId": "81ca9158-07bb-4413-fa19-e64467bb3197"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 18713),\n",
              " ('the', 13721),\n",
              " ('.', 6862),\n",
              " ('of', 6536),\n",
              " ('and', 6024),\n",
              " ('a', 4569),\n",
              " ('to', 4542),\n",
              " (';', 4072),\n",
              " ('in', 3916),\n",
              " ('that', 2982)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fd.get('barbed')) #barbed라는 단어만 찾아서 가져옴. 총 몇개있는지 출력\n",
        "print(fd.get('sport'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jm9fbkF_Ua8",
        "outputId": "fb97fc1a-4194-4323-a812-460d7fd09030"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1.concordance('school') #단어가 사용된 위치를 직접 표시해서 문맥이 어떤지 볼 수 있음. 25개까지 원래 출력가능한데 여기선 사용된 부분이 10개밖에 없어서 10개 출력함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyzLHteO_eXo",
        "outputId": "a96b5b2c-1949-40eb-f678-5bf06b381365"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 10 of 10 matches:\n",
            "Late Consumptive Usher to a Grammar School ) The pale Usher -- threadbare in c\n",
            "ality . \" While you take in hand to school others , and to teach them by what \n",
            " Pequod . She was a ship of the old school , rather small if anything ; with a\n",
            "ee - beam , about two miles off ! a school of them !\" Instantly all was commot\n",
            "d . In cavalier attendance upon the school of females , you invariably see a m\n",
            "whales is called by the fishermen a school , so is the lord and master of that\n",
            ", so is the lord and master of that school technically known as the schoolmast\n",
            "bly satirical , that after going to school himself , he should then go abroad \n",
            " . But strike a member of the harem school , and her companions swim around he\n",
            "he Pharaoh ' s . Methuselah seems a school - boy . I look round to shake hands\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1.similar('school') #같은 문맥에서 주어진 단어 대신 사용된 횟수가 높은 단어들을 찾는 기능, (school을 대신한 단어들)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW6DLPQ3_llC",
        "outputId": "3ddf930b-3569-4b4f-f6d7-7d0b892ba5c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man matter point cry sound whale roll day sea thing land king vessel\n",
            "way ship head voyage weight sort fire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1.common_contexts(['school','man']) #school, man 두 단어의 공통 문맥을 보는 기능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ-Lkgrz_7qg",
        "outputId": "e8d6cc79-ff45-40e0-a2c4-1c79cf4c0332"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_of the_of a_so\n"
          ]
        }
      ]
    }
  ]
}